# Titanic Kaggle Challenge

## Findings
Best Model: 79.9% Accuracy (Ensemble Random Forest Tree)

Given data about the passengers aboard the Titanic, I was able to predict their survival
with ~80% accuracy.

This model is 30% better than random guessing (50% accuracy).

## Other Models
* Model 1: 0.76555 (Logistic Regression) (Replacing NAs with Average of the column)
* Model 2: 0.78468 (Basic Decision Tree)
* Model 3: 0.79425 (Decision Tree, with Feature Engineering)
* Model 4: 0.76555 (Logistic Regression) (Replaced NAs using Decision Trees)

## Learning Outcomes
* Missing data and how to handle it
  * How missing data affects logistic regression vs trees
* Tested out the workflow I designed (see main folder for workflow)
